{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1beb4023",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9681981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (6.33.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (70.2.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cce0066e-8ac7-4746-9dcc-6a081a5e5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\.kaggle\\kaggle.json\n",
      "exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Option 1: Use raw string\n",
    "kaggle_json = os.path.expanduser(r\"~\\.kaggle\\kaggle.json\")\n",
    "\n",
    "# Option 2: Or use double backslashes\n",
    "# kaggle_json = os.path.expanduser(\"~\\\\.kaggle\\\\kaggle.json\")\n",
    "\n",
    "print(kaggle_json)\n",
    "print(\"exists:\", os.path.exists(kaggle_json))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df285a63-11ab-464e-bb47-c21bd617dec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nlp-getting-started.zip to c:\\Users\\LENOVO\\Downloads\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/593k [00:00<?, ?B/s]\n",
      "100%|██████████| 593k/593k [00:00<?, ?B/s]\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c nlp-getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61849610-4afe-46ee-a00d-f017590232d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a96e8f",
   "metadata": {},
   "source": [
    "!dir \"C:\\Users\\LENOVO\\Downloads\\nlp-getting-started\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c57dd6b-4ff7-4351-9306-c99463b06e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows-SSD\n",
      " Volume Serial Number is A2C5-BD47\n",
      "\n",
      " Directory of C:\\Users\\LENOVO\\Downloads\\nlp-getting-started\n",
      "\n",
      "02-11-2025  17:53    <DIR>          .\n",
      "02-11-2025  17:53    <DIR>          ..\n",
      "16-12-2019  20:36            22,746 sample_submission.csv\n",
      "16-12-2019  20:36           420,783 test.csv\n",
      "16-12-2019  20:36           987,712 train.csv\n",
      "               3 File(s)      1,431,241 bytes\n",
      "               2 Dir(s)  35,711,647,744 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls \"C:\\Users\\LENOVO\\Downloads\\nlp-getting-started\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a34d76f-3c24-45d7-88d1-fd55a8860af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\LENOVO\\\\Downloads\\\\nlp-getting-started\\\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d61113b-04c9-4332-a5eb-ff46d651f71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (2.1.2)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.9 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.9 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.9 kB ? eta -:--:--\n",
      "     -------------------------------------- 60.9/60.9 kB 539.3 kB/s eta 0:00:00\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/44.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.0/44.0 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     --------------------------------- ------ 51.2/60.8 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 60.8/60.8 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Collecting httpx<1,>=0.23.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting shellingham (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.10.23-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting click>=8.0.0 (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "   ---------------------------------------- 0.0/488.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 41.0/488.0 kB 1.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 61.4/488.0 kB 1.6 MB/s eta 0:00:01\n",
      "   ----- --------------------------------- 71.7/488.0 kB 653.6 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 92.2/488.0 kB 476.3 kB/s eta 0:00:01\n",
      "   ----------- -------------------------- 143.4/488.0 kB 774.0 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 174.1/488.0 kB 655.4 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 225.3/488.0 kB 724.0 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 256.0/488.0 kB 714.4 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 317.4/488.0 kB 785.7 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 317.4/488.0 kB 785.7 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 399.4/488.0 kB 802.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 471.0/488.0 kB 866.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 471.0/488.0 kB 866.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 488.0/488.0 kB 783.2 kB/s eta 0:00:00\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.1/12.8 MB 1.8 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.3/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.4/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.4/12.8 MB 1.7 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.4/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.5/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.6/12.8 MB 1.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.7/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.7/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.9/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.9/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.1/12.8 MB 1.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.2/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.3/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.4/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.6/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.6/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.7/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.8/12.8 MB 1.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.9/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.1/12.8 MB 1.9 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.2/12.8 MB 1.9 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.4/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.5/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.7/12.8 MB 2.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.8/12.8 MB 2.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.0/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.1/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.3/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.4/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.5/12.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.6/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.7/12.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.9/12.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.0/12.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.2/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.5/12.8 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/12.8 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/12.8 MB 2.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.3/12.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.6/12.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.9/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.1/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.4/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.7/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.0/12.8 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.4/12.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.7/12.8 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.2/12.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.5/12.8 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.9/12.8 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 9.2/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.5/12.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.9/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.1/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.3/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.9/12.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.0/12.8 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 5.7 MB/s eta 0:00:00\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/38.6 MB 9.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.8/38.6 MB 10.4 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.1/38.6 MB 9.1 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.4/38.6 MB 7.9 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.7/38.6 MB 7.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.9/38.6 MB 7.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.2/38.6 MB 6.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.2/38.6 MB 6.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.4/38.6 MB 5.9 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.8/38.6 MB 6.3 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.0/38.6 MB 6.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 3.0/38.6 MB 5.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.1/38.6 MB 5.1 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.3/38.6 MB 5.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.3/38.6 MB 5.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.3/38.6 MB 4.8 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.5/38.6 MB 4.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.7/38.6 MB 4.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.7/38.6 MB 4.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.7/38.6 MB 4.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.7/38.6 MB 3.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.2/38.6 MB 4.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.2/38.6 MB 4.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.2/38.6 MB 4.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.2/38.6 MB 4.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.2/38.6 MB 4.1 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.3/38.6 MB 3.5 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 4.4/38.6 MB 3.4 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.6/38.6 MB 3.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 4.9/38.6 MB 3.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.0/38.6 MB 3.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.3/38.6 MB 3.6 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.5/38.6 MB 3.6 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.8/38.6 MB 3.7 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.8/38.6 MB 3.7 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 6.1/38.6 MB 3.7 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 6.2/38.6 MB 3.6 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 6.2/38.6 MB 3.5 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.2/38.6 MB 3.5 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.2/38.6 MB 3.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.1/38.6 MB 3.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.3/38.6 MB 3.8 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.4/38.6 MB 3.7 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 7.5/38.6 MB 3.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 7.7/38.6 MB 3.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.0/38.6 MB 3.8 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.1/38.6 MB 3.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.6/38.6 MB 3.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 8.9/38.6 MB 4.0 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 9.2/38.6 MB 4.0 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 9.7/38.6 MB 4.1 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 10.0/38.6 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 10.4/38.6 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 10.7/38.6 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 10.9/38.6 MB 4.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 11.5/38.6 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 11.6/38.6 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 11.8/38.6 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.2/38.6 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.5/38.6 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 12.8/38.6 MB 4.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 13.0/38.6 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 13.4/38.6 MB 4.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 13.9/38.6 MB 4.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 14.0/38.6 MB 5.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.4/38.6 MB 5.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 14.7/38.6 MB 5.7 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 14.9/38.6 MB 5.7 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 15.3/38.6 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 15.7/38.6 MB 6.0 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 15.8/38.6 MB 5.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 16.1/38.6 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 16.5/38.6 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 16.9/38.6 MB 6.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 17.3/38.6 MB 6.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 17.7/38.6 MB 6.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 17.8/38.6 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.1/38.6 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.6/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 18.8/38.6 MB 6.9 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.4/38.6 MB 7.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.7/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 19.9/38.6 MB 6.9 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.4/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 20.6/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 21.1/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.4/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.6/38.6 MB 6.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 21.9/38.6 MB 6.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.4/38.6 MB 7.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.7/38.6 MB 7.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 23.0/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.3/38.6 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.6/38.6 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.8/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.0/38.6 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.4/38.6 MB 7.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.6/38.6 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 25.0/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.3/38.6 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.7/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.1/38.6 MB 7.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.4/38.6 MB 7.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 26.8/38.6 MB 7.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.0/38.6 MB 7.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.5/38.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.9/38.6 MB 7.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.1/38.6 MB 7.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.5/38.6 MB 7.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.8/38.6 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.0/38.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.4/38.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.7/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 29.9/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.1/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.1/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.1/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.1/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.1/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.1/38.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.3/38.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.4/38.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.5/38.6 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.5/38.6 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.6/38.6 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.6/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.6/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.7/38.6 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.7/38.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.8/38.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.8/38.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.8/38.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.8/38.6 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.8/38.6 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.9/38.6 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.9/38.6 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.9/38.6 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 30.9/38.6 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.0/38.6 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.0/38.6 MB 4.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.0/38.6 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.0/38.6 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.1/38.6 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.1/38.6 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.1/38.6 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.1/38.6 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.1/38.6 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.2/38.6 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.2/38.6 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.2/38.6 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.2/38.6 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.4/38.6 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 31.6/38.6 MB 3.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 31.9/38.6 MB 3.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 31.9/38.6 MB 3.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 32.1/38.6 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.3/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.7/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 32.8/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.1/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.2/38.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.5/38.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 33.8/38.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.1/38.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.4/38.6 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 34.8/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.2/38.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 35.6/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.0/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.3/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.6/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.0/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.4/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.6/38.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 3.2 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.6/12.0 MB 12.9 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.9/12.0 MB 9.7 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.4/12.0 MB 12.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.1/12.0 MB 11.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.7/12.0 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.6/12.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.0/12.0 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.5/12.0 MB 10.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.8/12.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.2/12.0 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.6/12.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.8/12.0 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.2/12.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.6/12.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.9/12.0 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.2/12.0 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.7/12.0 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.0/12.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.5/12.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.8/12.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.3/12.0 MB 9.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.4/12.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.8/12.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.1/12.0 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.6/12.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 566.1/566.1 kB 17.9 MB/s eta 0:00:00\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Downloading regex-2025.10.23-cp312-cp312-win_amd64.whl (276 kB)\n",
      "   ---------------------------------------- 0.0/276.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 276.9/276.9 kB 8.6 MB/s eta 0:00:00\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Installing collected packages: threadpoolctl, safetensors, regex, pyyaml, numpy, joblib, scipy, huggingface-hub, tokenizers, scikit-learn, transformers, sentence-transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed huggingface-hub-0.36.0 joblib-1.5.2 numpy-2.3.4 pyyaml-6.0.3 regex-2025.10.23 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.3 sentence-transformers-5.1.2 threadpoolctl-3.6.0 tokenizers-0.22.1 transformers-4.57.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\LENOVO\\Desktop\\Hardcore ML\\Mlenv\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\LENOVO\\Desktop\\Hardcore ML\\Mlenv\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers scikit-learn pandas numpy joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2adc213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (70.2.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.8 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.8 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.8 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.8 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.8 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.8 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.8 MB 330.3 kB/s eta 0:00:06\n",
      "    --------------------------------------- 0.0/1.8 MB 330.3 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/1.8 MB 131.3 kB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.1/1.8 MB 131.3 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.1/1.8 MB 180.8 kB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.1/1.8 MB 204.8 kB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.1/1.8 MB 204.8 kB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.1/1.8 MB 213.0 kB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.2/1.8 MB 249.8 kB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.2/1.8 MB 249.8 kB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 0.3/1.8 MB 327.7 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.3/1.8 MB 361.4 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.3/1.8 MB 373.1 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.4/1.8 MB 397.9 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.4/1.8 MB 397.9 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.4/1.8 MB 422.5 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.4/1.8 MB 422.5 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.6/1.8 MB 544.8 kB/s eta 0:00:03\n",
      "   ------------ --------------------------- 0.6/1.8 MB 544.8 kB/s eta 0:00:03\n",
      "   -------------- ------------------------- 0.7/1.8 MB 607.9 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.7/1.8 MB 607.9 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.7/1.8 MB 578.0 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 629.9 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.8 MB 599.5 kB/s eta 0:00:02\n",
      "   --------------------- ------------------ 0.9/1.8 MB 701.7 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 746.0 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.2/1.8 MB 837.6 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 890.7 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.8 MB 873.8 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.8 MB 878.7 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.4/1.8 MB 878.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.6/1.8 MB 957.8 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 992.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.7/1.8 MB 992.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 1.0 MB/s eta 0:00:00\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\LENOVO\\Desktop\\Hardcore ML\\Mlenv\\Scripts\\python.exe -m pip install -U pip setuptools wheel\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\desktop\\hardcore ml\\mlenv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U numpy scikit-learn pandas sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae7564a-6c90-4c12-9a7d-cb5ee368204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Desktop\\Hardcore ML\\Mlenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.7.2\n",
      "pandas: 2.3.3\n",
      "numpy: 2.3.4\n",
      "sBERT: 5.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Desktop\\Hardcore ML\\Mlenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\LENOVO\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "import sklearn, pandas, numpy, sentence_transformers\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"pandas:\", pandas.__version__)\n",
    "print(\"numpy:\", numpy.__version__)\n",
    "print(\"sBERT:\", sentence_transformers.__version__)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "m = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "emb = m.encode([\"Cyclone warning near Odisha coast\", \"Cute cat video\"], normalize_embeddings=True)\n",
    "print(emb.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc74e48-dc41-4291-a49c-4f2f69dc3bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Python: c:\\Users\\LENOVO\\Desktop\\Hardcore ML\\Mlenv\\Scripts\\python.exe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "print(\"Kernel Python:\", sys.executable)\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"sentence-transformers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1d5a9-7175-44eb-9c0b-9fbbfd534af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers: 5.1.2\n",
      "sklearn: 1.7.2 pandas: 2.3.3 numpy: 2.3.4\n",
      "Embedding shape: (1, 384)\n"
     ]
    }
   ],
   "source": [
    "    import sentence_transformers, sklearn, pandas, numpy\n",
    "    print(\"sentence-transformers:\", sentence_transformers.__version__)\n",
    "    print(\"sklearn:\", sklearn.__version__, \"pandas:\", pandas.__version__, \"numpy:\", numpy.__version__)\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    m = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "    print(\"Embedding shape:\", m.encode([\"ok\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd99f647-533d-4189-bf8a-e144e89ae6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6471 Val size: 1142\n",
      "Label dist (train):\n",
      " target\n",
      "0    0.570391\n",
      "1    0.429609\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 26/26 [00:39<00:00,  1.50s/it]\n",
      "Batches: 100%|██████████| 5/5 [00:07<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8465    0.8387    0.8426       651\n",
      "           1     0.7887    0.7984    0.7935       491\n",
      "\n",
      "    accuracy                         0.8214      1142\n",
      "   macro avg     0.8176    0.8185    0.8181      1142\n",
      "weighted avg     0.8217    0.8214    0.8215      1142\n",
      "\n",
      "{'precision': 0.7887323943661971, 'recall': 0.7983706720977597, 'f1': 0.7935222672064778}\n",
      "Saved to: artifacts/slm_relevance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, re, numpy as np, pandas as pd, joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_fscore_support\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ========= Config =========\n",
    "DATA_CSV = \"C:\\\\Users\\\\LENOVO\\\\Downloads\\\\nlp-getting-started\\\\train.csv\"  # adjust path if needed\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"target\"   # 1=relevant, 0=irrelevant (from Kaggle disaster tweets)\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "ARTIFACT_DIR = \"artifacts/slm_relevance\"   # where to save models/embeddings\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "# ========= Load & clean =========\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "df = df[[TEXT_COL, LABEL_COL]].dropna()\n",
    "df[TEXT_COL] = df[TEXT_COL].astype(str)\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)          # links\n",
    "    s = re.sub(r\"#(\\w+)\", r\"\\1\", s)                  # hashtags -> word\n",
    "    s = re.sub(r\"@\\w+\", \" \", s)                      # mentions\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"clean\"] = df[TEXT_COL].apply(clean_text)\n",
    "\n",
    "# stratified split\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.15, random_state=42, stratify=df[LABEL_COL]\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_df), \"Val size:\", len(val_df))\n",
    "print(\"Label dist (train):\\n\", train_df[LABEL_COL].value_counts(normalize=True))\n",
    "\n",
    "# ========= Encode with SentenceTransformer (CPU) =========\n",
    "st_model = SentenceTransformer(MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "def embed(texts, batch_size=256):\n",
    "    return st_model.encode(\n",
    "        texts, batch_size=batch_size, convert_to_numpy=True, show_progress_bar=True, normalize_embeddings=True\n",
    "    )\n",
    "\n",
    "X_train = embed(train_df[\"clean\"].tolist())\n",
    "y_train = train_df[LABEL_COL].values.astype(int)\n",
    "\n",
    "X_val = embed(val_df[\"clean\"].tolist())\n",
    "y_val = val_df[LABEL_COL].values.astype(int)\n",
    "\n",
    "np.save(os.path.join(ARTIFACT_DIR, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(ARTIFACT_DIR, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(ARTIFACT_DIR, \"X_val.npy\"),   X_val)\n",
    "np.save(os.path.join(ARTIFACT_DIR, \"y_val.npy\"),   y_val)\n",
    "\n",
    "# ========= Train a lightweight classifier =========\n",
    "# class_weight='balanced' handles imbalance nicely\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=1,\n",
    "    C=2.0,            # a bit more capacity than default\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ========= Evaluate =========\n",
    "pred = clf.predict(X_val)\n",
    "proba = clf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(classification_report(y_val, pred, digits=4))\n",
    "p, r, f1, _ = precision_recall_fscore_support(y_val, pred, average=\"binary\")\n",
    "print({\"precision\": p, \"recall\": r, \"f1\": f1})\n",
    "\n",
    "# ========= Save artifacts =========\n",
    "joblib.dump(clf, os.path.join(ARTIFACT_DIR, \"lr_relevance.joblib\"))\n",
    "st_model.save(os.path.join(ARTIFACT_DIR, \"sbert_model\"))  # saves config + modules\n",
    "\n",
    "print(\"Saved to:\", ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4220349a-32e3-4d0b-8c75-f84105d0766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ARTIFACT_DIR = \"artifacts/slm_relevance\"\n",
    "SBERT_PATH   = f\"{ARTIFACT_DIR}/sbert_model\"\n",
    "LR_PATH      = f\"{ARTIFACT_DIR}/lr_relevance.joblib\"\n",
    "\n",
    "_sbert = SentenceTransformer(SBERT_PATH, device=\"cpu\")\n",
    "_lr    = joblib.load(LR_PATH)\n",
    "\n",
    "def predict_relevance(text: str, threshold: float = 0.5):\n",
    "    if not text or not text.strip():\n",
    "        return False, 0.0\n",
    "    emb = _sbert.encode([text], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    p = float(_lr.predict_proba(emb)[0, 1])\n",
    "    return (p >= threshold, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f72595-4c0b-471a-ae9d-c43ab848ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 0.9707210675201318)\n",
      "(True, 0.9707210675201318)\n",
      "(True, 0.8609894408834318)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(predict_relevance(\"Severe flooding reported near Puri beach\"))\n",
    "# -> (True, 0.87)  for examplefrom slm_infer import predict_relevance\n",
    "print(predict_relevance(\"Severe flooding reported near Puri beach\"))\n",
    "# -> (True, 0.87)  for example3\n",
    "\n",
    "print(predict_relevance(\"Never seen anything like this before... pray for us 🙏 #TsunamiAlert\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456eba03",
   "metadata": {},
   "source": [
    "# MODEL 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023cf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np, pandas as pd, joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e77d6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Config =========\n",
    "DATA_CSV = \"C:\\\\Users\\\\LENOVO\\\\Downloads\\\\archive\\\\final_dataset_mini_balanced.csv\"  # <- you’ll prepare this\n",
    "TEXT_COL = \"text\"\n",
    "LABEL_COL = \"label\"   # e.g. tsunami, earthquake, cyclone, etc.\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "ARTIFACT_DIR = \"artifacts/slm_calamity\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "062933c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 80980 Val size: 14291\n",
      "Label dist (train):\n",
      " label\n",
      "Hurricane              0.090911\n",
      "Drought                0.090911\n",
      "Industrial Accident    0.090911\n",
      "Wildfire               0.090911\n",
      "Tsunami                0.090911\n",
      "Typhoon                0.090911\n",
      "Volcanic Eruption      0.090911\n",
      "Earthquake             0.090911\n",
      "Cyclone                0.090911\n",
      "Flood                  0.090899\n",
      "Non-Disaster           0.090899\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ========= Load & clean =========\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "df = df[[TEXT_COL, LABEL_COL]].dropna()\n",
    "df[TEXT_COL] = df[TEXT_COL].astype(str)\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)          # links\n",
    "    s = re.sub(r\"#(\\w+)\", r\"\\1\", s)                  # hashtags -> word\n",
    "    s = re.sub(r\"@\\w+\", \" \", s)                      # mentions\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"clean\"] = df[TEXT_COL].apply(clean_text)\n",
    "\n",
    "# stratified split\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.15, random_state=42, stratify=df[LABEL_COL]\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_df), \"Val size:\", len(val_df))\n",
    "print(\"Label dist (train):\\n\", train_df[LABEL_COL].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1565fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 6b6e9857-ca20-4c61-aa09-213c24e92877)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: eccf91b4-b116-43bf-87e0-78c6f9642b16)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e340f6fe-6967-4ba0-b68f-66f63a1de05b)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "Batches: 100%|██████████| 317/317 [05:21<00:00,  1.02s/it]\n",
      "Batches: 100%|██████████| 56/56 [00:53<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# ========= Encode with SentenceTransformer =========\n",
    "st_model = SentenceTransformer(MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "def embed(texts, batch_size=256):\n",
    "    return st_model.encode(\n",
    "        texts, batch_size=batch_size, convert_to_numpy=True, \n",
    "        show_progress_bar=True, normalize_embeddings=True\n",
    "    )\n",
    "\n",
    "X_train = embed(train_df[\"clean\"].tolist())\n",
    "y_train = train_df[LABEL_COL].values\n",
    "\n",
    "X_val = embed(val_df[\"clean\"].tolist())\n",
    "y_val = val_df[LABEL_COL].values\n",
    "\n",
    "np.save(os.path.join(ARTIFACT_DIR, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(ARTIFACT_DIR, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(ARTIFACT_DIR, \"X_val.npy\"),   X_val)\n",
    "np.save(os.path.join(ARTIFACT_DIR, \"y_val.npy\"),   y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "806bb51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\Desktop\\Hardcore ML\\Mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=2.0, class_weight=&#x27;balanced&#x27;, max_iter=2000,\n",
       "                   multi_class=&#x27;multinomial&#x27;, n_jobs=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">2.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">2000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;multinomial&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(C=2.0, class_weight='balanced', max_iter=2000,\n",
       "                   multi_class='multinomial', n_jobs=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= Train Multiclass Logistic Regression =========\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=1,\n",
    "    C=2.0,\n",
    "    solver=\"lbfgs\",\n",
    "    multi_class=\"multinomial\"\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "549d5d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "            Cyclone     0.9992    0.9985    0.9988      1299\n",
      "            Drought     0.9992    1.0000    0.9996      1299\n",
      "         Earthquake     0.9969    0.9977    0.9973      1299\n",
      "              Flood     0.9977    0.9985    0.9981      1300\n",
      "          Hurricane     0.9977    0.9992    0.9985      1299\n",
      "Industrial Accident     1.0000    1.0000    1.0000      1299\n",
      "       Non-Disaster     0.9985    1.0000    0.9992      1300\n",
      "            Tsunami     0.9969    0.9969    0.9969      1299\n",
      "            Typhoon     1.0000    1.0000    1.0000      1299\n",
      "  Volcanic Eruption     1.0000    0.9985    0.9992      1299\n",
      "           Wildfire     1.0000    0.9969    0.9985      1299\n",
      "\n",
      "           accuracy                         0.9987     14291\n",
      "          macro avg     0.9987    0.9987    0.9987     14291\n",
      "       weighted avg     0.9987    0.9987    0.9987     14291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========= Evaluate =========\n",
    "pred = clf.predict(X_val)\n",
    "print(classification_report(y_val, pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea1f5298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved Model 2 (Calamity Classifier) to: artifacts/slm_calamity\n"
     ]
    }
   ],
   "source": [
    "# ========= Save =========\n",
    "joblib.dump(clf, os.path.join(ARTIFACT_DIR, \"lr_calamity.joblib\"))\n",
    "st_model.save(os.path.join(ARTIFACT_DIR, \"model2_model\"))\n",
    "\n",
    "print(\"✅ Saved Model 2 (Calamity Classifier) to:\", ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69a13a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ARTIFACT_DIR = \"artifacts/slm_calamity\"\n",
    "SBERT_PATH   = f\"{ARTIFACT_DIR}/model2_model\"\n",
    "LR_PATH      = f\"{ARTIFACT_DIR}/lr_calamity.joblib\"\n",
    "\n",
    "_sbert = SentenceTransformer(SBERT_PATH, device=\"cpu\")\n",
    "_lr    = joblib.load(LR_PATH)\n",
    "\n",
    "def predict_calamity(text: str):\n",
    "    \"\"\"\n",
    "    Predicts the type of calamity for a given text.\n",
    "    Returns: (predicted_label, {label:prob})\n",
    "    \"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return \"unknown\", {}\n",
    "\n",
    "    emb = _sbert.encode([text], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    probs = _lr.predict_proba(emb)[0]\n",
    "    labels = _lr.classes_\n",
    "\n",
    "    result = dict(zip(labels, probs))\n",
    "    top_label = labels[np.argmax(probs)]\n",
    "    return top_label, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e590818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tsunami', {'Cyclone': np.float64(7.753986171167451e-05), 'Drought': np.float64(6.290662878554927e-07), 'Earthquake': np.float64(4.016229787143221e-05), 'Flood': np.float64(1.406455432832646e-05), 'Hurricane': np.float64(1.8001213529544028e-05), 'Industrial Accident': np.float64(7.685518262552306e-07), 'Non-Disaster': np.float64(2.271672597673885e-06), 'Tsunami': np.float64(0.9996866643933386), 'Typhoon': np.float64(7.203334310228347e-05), 'Volcanic Eruption': np.float64(8.512471645029883e-05), 'Wildfire': np.float64(2.740328956035973e-06)})\n",
      "('Earthquake', {'Cyclone': np.float64(0.01823908246907371), 'Drought': np.float64(1.3720937474047673e-05), 'Earthquake': np.float64(0.9654338977134825), 'Flood': np.float64(1.1070738061796579e-05), 'Hurricane': np.float64(8.774596103254954e-06), 'Industrial Accident': np.float64(0.0011380022334749739), 'Non-Disaster': np.float64(0.000986324308740537), 'Tsunami': np.float64(0.00013988484704904148), 'Typhoon': np.float64(4.714610933175205e-05), 'Volcanic Eruption': np.float64(0.013826285068302503), 'Wildfire': np.float64(0.0001558109789058657)})\n",
      "('Cyclone', {'Cyclone': np.float64(0.5826072278453689), 'Drought': np.float64(0.2897793851686558), 'Earthquake': np.float64(0.00850165957030556), 'Flood': np.float64(0.0016577201724468156), 'Hurricane': np.float64(0.05758763841056457), 'Industrial Accident': np.float64(0.0005267678822484575), 'Non-Disaster': np.float64(0.01727992314744337), 'Tsunami': np.float64(0.00025936003560796627), 'Typhoon': np.float64(0.024138412398094833), 'Volcanic Eruption': np.float64(0.013863917054856291), 'Wildfire': np.float64(0.0037979883144074176)})\n",
      "('Earthquake', {'Cyclone': np.float64(4.7383773824385466e-05), 'Drought': np.float64(0.0002525708137602496), 'Earthquake': np.float64(0.887374088869676), 'Flood': np.float64(0.005631114372811931), 'Hurricane': np.float64(0.0007220444411761057), 'Industrial Accident': np.float64(0.014379395113330588), 'Non-Disaster': np.float64(0.08186661067919589), 'Tsunami': np.float64(0.0029302695482519158), 'Typhoon': np.float64(0.00029929772920548524), 'Volcanic Eruption': np.float64(0.005657393867957084), 'Wildfire': np.float64(0.0008398307908105063)})\n"
     ]
    }
   ],
   "source": [
    "print(predict_calamity(\"Tsunami waves approaching Chennai coast\"))\n",
    "# → ('tsunami', {'tsunami': 0.91, 'cyclone': 0.05, 'earthquake': 0.01, ...})\n",
    "\n",
    "print(predict_calamity(\"Massive tremors felt in Delhi\"))\n",
    "# → ('earthquake', {...})\n",
    "\n",
    "print(predict_calamity(\"Heavy rainfall and strong winds near Odisha\"))\n",
    "# → ('cyclone', {...})\n",
    "\n",
    "print(predict_calamity(\"we humped so hard that the bed broke like an earthquake\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f53b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(Mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
